{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://python.langchain.com/docs/how_to/structured_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from langchain_ibm import ChatWatsonx\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from pydantic import BaseModel, ValidationError, Field\n",
    "from typing import Any, Optional, List\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ['ANTHROPIC_API_KEY']\n",
    "# base_url = os.environ['WATSONX_URL']\n",
    "# project_id = os.environ['WATSONX_PROJECT_ID']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_gen = itertools.count(start=0)\n",
    "\n",
    "def p(d):\n",
    "    return f\"{d.metadata['id']} {d.metadata.get('annotation', '')} ({d.metadata['start']}, {d.metadata['end']})\"\n",
    "\n",
    "def split_text(fn) -> List[Document]:\n",
    "    pattern = r'\\n\\s*\\n'\n",
    "    \n",
    "    with open(fn, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    splits = {}\n",
    "    previous_end = 0\n",
    "    for match in re.finditer(pattern, content):\n",
    "        start, end = match.span()\n",
    "        d = Document(\n",
    "            page_content = content[previous_end:start], \n",
    "            metadata = dict(id = f\"B{next(id_gen)}\", start = previous_end, end = start, filename = fn)\n",
    "        )\n",
    "        splits[d.metadata['id']] = d\n",
    "        previous_end = end\n",
    "    d = Document(\n",
    "            page_content = content[previous_end:], \n",
    "            metadata = dict(id = f\"B{next(id_gen)}\", start = previous_end, end = len(content), filename = fn)\n",
    "    )\n",
    "    splits[d.metadata['id']] = d\n",
    "    return splits\n",
    "\n",
    "lhs_file = \"../frontend/public/data/SHA-1/selected-text.txt\"\n",
    "rhs_file = \"../frontend/public/data/SHA-1/pre-written.txt\"\n",
    "annotations_file = \"../frontend/public/data/SHA-1/annotations.json\"\n",
    "\n",
    "lhs_bs = split_text(lhs_file)\n",
    "rhs_bs = split_text(rhs_file)\n",
    "len(lhs_bs), len(rhs_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "lhs_fs, rhs_fs = {}, {}\n",
    "content = {}\n",
    "\n",
    "with open(annotations_file, \"r\") as file:\n",
    "    annotations = json.load(file)\n",
    "with open(lhs_file, 'r') as f:\n",
    "    content[\"lhs\"] = f.read()\n",
    "with open(rhs_file, 'r') as f:\n",
    "    content[\"rhs\"] = f.read()\n",
    "\n",
    "def create_document(d, idx, side, fn):\n",
    "    return Document(\n",
    "        page_content= content[side][d['start']:d['end']], \n",
    "        metadata = dict(id = f\"F{next(id_gen)}\", \n",
    "         start = d['start'], end = d['end'], annotation = idx, filename = fn)\n",
    "    )\n",
    "\n",
    "for i, a in enumerate(annotations['mappings']):\n",
    "    for d in a.get('lhsRanges', []):\n",
    "        doc = create_document(d, i, \"lhs\", lhs_file)\n",
    "        lhs_fs[doc.metadata['id']] = doc\n",
    "    for d in a.get('rhsRanges', []):\n",
    "        doc = create_document(d, i, \"rhs\", rhs_file)\n",
    "        rhs_fs[doc.metadata['id']] = doc\n",
    "\n",
    "len(lhs_fs), len(rhs_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B0', 'B30'),\n",
       " ('B0', 'B33'),\n",
       " ('B0', 'B34'),\n",
       " ('B0', 'B36'),\n",
       " ('B1', 'B33'),\n",
       " ('B2', 'B33'),\n",
       " ('B4', 'B34'),\n",
       " ('B6', 'B30'),\n",
       " ('B6', 'B36'),\n",
       " ('B11', 'B36'),\n",
       " ('B11', 'B37'),\n",
       " ('B12', 'B36'),\n",
       " ('B12', 'B37'),\n",
       " ('B13', 'B30'),\n",
       " ('B13', 'B33'),\n",
       " ('B13', 'B34'),\n",
       " ('B13', 'B36')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_range(a, b):\n",
    "    ai, ae = a.metadata['start'], a.metadata['end']\n",
    "    assert ai <= ae\n",
    "    bi, be = b.metadata['start'], b.metadata['end'] \n",
    "    assert bi <= be\n",
    "    if bi <= ai and ae <= be:\n",
    "        return 1 # A inside B\n",
    "    elif ai <= bi and be <= ae:\n",
    "        return 2 # B inside A\n",
    "    elif ae < bi or be < ai:\n",
    "        return 3 # A and B disjoint\n",
    "    else:\n",
    "        return 4 # A and B intersect\n",
    "\n",
    "def coverage(bs, fs):\n",
    "    f = lambda d: d.metadata['end']\n",
    "    list1 = sorted(bs.values(), key = f)\n",
    "    list2 = sorted(fs.values(), key = f)\n",
    "    blocks = {i.metadata['id']: [] for i in list1}\n",
    "    for a in list1:\n",
    "        for b in list2[:]:\n",
    "            if is_range(b,a) == 1:\n",
    "                blocks[a.metadata['id']].append(b.metadata['id'])\n",
    "                list2.remove(b)\n",
    "    assert len(list2) == 0\n",
    "    return blocks\n",
    "\n",
    "lhs_map = coverage(lhs_bs, lhs_fs)\n",
    "rhs_map = coverage(rhs_bs, rhs_fs)\n",
    "lhs_map\n",
    "\n",
    "def custom_str(self):\n",
    "    return f\"{self.metadata['id']} {self.metadata.get('annotation','NA')} ({self.metadata['start']},{self.metadata['end']})\"\n",
    "\n",
    "Document.__str__ = custom_str\n",
    "\n",
    "def print_map(m, db, df):\n",
    "    for k,v in m.items():\n",
    "        print(db[k], [f'{df[i]}' for i in v])\n",
    "\n",
    "# print_map(lhs_map, lhs_bs, lhs_fs)\n",
    "\n",
    "bmaps = []\n",
    "for bl, vl in lhs_map.items():\n",
    "    ansl = [lhs_fs[k].metadata['annotation'] for k in vl]\n",
    "    for br, vr in rhs_map.items():\n",
    "        ansr = [rhs_fs[k].metadata['annotation'] for k in vr]\n",
    "        if set(ansl) & set(ansr):\n",
    "            bmaps.append( (bl, br) )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for a, b in bmaps:\n",
    "    print(f'---ANN \\n{lhs_bs[a].page_content}\\n~~~\\n{rhs_bs[b].page_content}\\n')\n",
    "\"\"\"\n",
    "bmaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOllama(\n",
    "    model = \"llama3.2:3b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    model = 'claude-3-7-sonnet-20250219',\n",
    "    temperature=0,\n",
    "    max_tokens=3000,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key= api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotation(BaseModel):\n",
    "    lhsText     : str = Field(description=\"the fragments of the LHS text\")\n",
    "    rhsText     : str = Field(description=\"the fragments of the RHS text\")\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"*** TEXT {text} \\n\\n*** CODE {code}\"),\n",
    "        (\"ai\", \"{status}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=[dict(\n",
    "        text = lhs_bs[m[0]].page_content, \n",
    "        code = rhs_bs[m[1]].page_content,\n",
    "        status = \"related\"\n",
    "        ) for m in random.sample(bmaps, 5)]\n",
    ")\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "template = env.get_template('ar-prompt.text')\n",
    "instruction = template.render(\n",
    "    lhs = \"\\n~~~\\n\".join([b.page_content for b in lhs_bs.values()]), \n",
    "    rhs = \"\\n~~~\\n\".join([b.page_content for b in rhs_bs.values()])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RunnablePassthrough' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      6\u001b[39m final_prompt = ChatPromptTemplate.from_messages(\n\u001b[32m      7\u001b[39m     [\n\u001b[32m      8\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mteste\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     ]\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# structured_chat = chat.with_structured_output(Annotation)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# chain = final_prompt # | structured_chat \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m chain = {\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mRunnablePassthrough\u001b[49m(), \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m : RunnablePassthrough()} | few_shot_prompt \n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lk, lv \u001b[38;5;129;01min\u001b[39;00m lhs_bs:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m rk, rv \u001b[38;5;129;01min\u001b[39;00m rhs_bs:\n",
      "\u001b[31mNameError\u001b[39m: name 'RunnablePassthrough' is not defined"
     ]
    }
   ],
   "source": [
    "# import jsondiff as jd\n",
    "# from jsondiff import diff, JsonDiffer\n",
    "# import statistics\n",
    "# jd = JsonDiffer()\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", instruction),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"*** TEXT {input} \\n*** CODE {code}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# structured_chat = chat.with_structured_output(Annotation)\n",
    "# chain = final_prompt # | structured_chat \n",
    "chain = {\"input\": RunnablePassthrough(), \"code\" : RunnablePassthrough()} | few_shot_prompt \n",
    "\n",
    "for lk, lv in lhs_bs:\n",
    "    for rk, rv in rhs_bs:\n",
    "        try:\n",
    "            res = chain.invoke({\"input\": lv.page_content, \"code\": rv.page_content})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        else:\n",
    "            print(f\"lhs: {lk}  rhs: {rk} response: {res}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
